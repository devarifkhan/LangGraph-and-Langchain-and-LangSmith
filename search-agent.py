from typing import List
from pydantic import BaseModel, Field
from dotenv import load_dotenv
from langchain.agents import create_agent
from langchain_core.messages import HumanMessage
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_tavily import TavilySearch

load_dotenv()


class Source(BaseModel):
    url: str = Field(..., description="The URL of the source")


class AgentResponse(BaseModel):
    answer: str = Field(..., description="The answer generated by the agent")
    sources: List[Source] = Field(..., description="List of sources used to generate the answer")


# Define a Pydantic model for the agent input
class AgentInput(BaseModel):
    messages: List[HumanMessage]


llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash")
tools = [TavilySearch()]
agent = create_agent(model=llm, tools=tools, response_format=AgentResponse)


def main():
    print("Hello from langchain agent")

    # Wrap the messages in the AgentInput model
    input_data = AgentInput(messages=[HumanMessage(content="what is the weather of dhaka?")])

    # Pass the BaseModel to agent.invoke
    result: AgentResponse = agent.invoke(input_data)

    print("Agent result:", result)


if __name__ == "__main__":
    main()
